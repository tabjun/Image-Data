{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15Xu4tQojMy7gyKNEO3bsYVyAeW-AjS41",
      "authorship_tag": "ABX9TyO+Rf3EbqmbCjkYTh5I/ZuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabjun/Image-Data/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip  install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YsI_osje1ma",
        "outputId": "a0366c46-f407-4efa-bfe4-42a81647a507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (533 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import shap"
      ],
      "metadata": {
        "id": "hMEVaKCxYVVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "3846a29f-ffef-4cf8-ac5b-6beda9f49423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-485d65cfdae6>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "print(len(train_images))\n",
        "print(len(train_labels))\n",
        "\n",
        "print(len(test_images))\n",
        "print(len(test_labels))"
      ],
      "metadata": {
        "id": "0ApmzTkUXrmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "train_images = train_images.reshape((len(train_images), -1))\n",
        "test_images = test_images.reshape((len(test_images), -1))\n",
        "scaler = StandardScaler()\n",
        "train_images = scaler.fit_transform(train_images)\n",
        "test_images = scaler.transform(test_images)\n",
        "\n",
        "# Define PCA and fit on training data\n",
        "pca = PCA(n_components=2)  # Choose the number of components\n",
        "pca.fit(train_images)\n",
        "\n",
        "print(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "eVR4n2-LRLzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data using PCA\n",
        "train_images_pca = pca.transform(train_images)\n",
        "test_images_pca = pca.transform(test_images)\n",
        "\n",
        "# Reconstruct images from PCA components\n",
        "reconstructed_train_images = pca.inverse_transform(train_images_pca)\n",
        "reconstructed_test_images = pca.inverse_transform(test_images_pca)\n",
        "\n",
        "# Visualize original and reconstructed images\n",
        "def plot_images(original, reconstructed):\n",
        "    n = 10  # Number of images to display\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # Original Images\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n",
        "        plt.title('Original')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Reconstructed Images\n",
        "        ax = plt.subplot(2, n, i + n + 1)\n",
        "        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
        "        plt.title('Reconstructed')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_images(train_images, reconstructed_train_images)"
      ],
      "metadata": {
        "id": "XOOfu1uISagB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize a Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the classifier on the PCA-transformed training data\n",
        "rf.fit(train_images_pca, train_labels)\n",
        "\n",
        "# Predict labels for test data using the trained classifier\n",
        "predicted_labels = rf.predict(test_images_pca)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted_labels)\n",
        "print(f\" PCA-transformed data: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "0xl85yUNRjde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=50)\n",
        "X_r = pca.fit(X).transform(X)\n",
        "\n",
        "plt.plot(range(10), pca.explained_variance_ratio_)\n",
        "plt.plot(range(10), np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title(\"Component-wise and Cumulative Explained Variance\")\n",
        "pass"
      ],
      "metadata": {
        "id": "ar9kdjHbZZi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import ensemble\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble"
      ],
      "metadata": {
        "id": "WKKR53PcXtDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. LR Model\n",
        "start1 = time.time()\n",
        "\n",
        "logistic = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "logistic.fit(train_images_pca, train_labels)\n",
        "\n",
        "end1 = time.time()\n",
        "lr_time = end1-start1\n",
        "\n",
        "# 2. SVC Model\n",
        "start2 = time.time()\n",
        "\n",
        "svc = SVC(C=13,kernel='rbf',gamma=\"auto\",probability = True)\n",
        "svc.fit(train_images_pca, train_labels)\n",
        "\n",
        "end2 = time.time()\n",
        "svm_time = end2-start2\n",
        "\n",
        "# 3. Random Forest\n",
        "start3 = time.time()\n",
        "\n",
        "random_forest = RandomForestClassifier(criterion='entropy', max_depth=70, n_estimators=100)\n",
        "random_forest.fit(train_images_pca, train_labels)\n",
        "\n",
        "end3 = time.time()\n",
        "forest_time = end3-start3\n",
        "\n",
        "# 4. Gradient Boosting Method\n",
        "start4 = time.time()\n",
        "\n",
        "Gradient = ensemble.GradientBoostingClassifier(n_estimators=100)\n",
        "Gradient.fit(train_images_pca, train_labels)\n",
        "\n",
        "end4 = time.time()\n",
        "gradient_time = end4-start4\n",
        "\n",
        "# 5. XGBoost Method\n",
        "start5 = time.time()\n",
        "\n",
        "xgb = XGBClassifier(use_label_encoder=False,objective=\"multi:softmax\",eval_metric=\"merror\")\n",
        "xgb.fit(train_images_pca, train_labels.ravel())\n",
        "\n",
        "end5 = time.time()\n",
        "xgb_time = end5-start5\n",
        "\n",
        "\n",
        "print(\"LR Time: {:0.2f} minute\".format(lr_time/60.0))\n",
        "print(\"SVC Time: {:0.2f} minute\".format(svm_time/60.0))\n",
        "print(\"Random Forest Time: {:0.2f} minute\".format(forest_time/60.0))\n",
        "print(\"Gradient Boosting Time: {:0.2f} minute\".format(gradient_time/60.0))\n",
        "print(\"XGBoost Time: {:0.2f} minute\".format(xgb_time/60.0))"
      ],
      "metadata": {
        "id": "JIiYd8IUXei8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic\n",
        "y_train_lr = logistic.predict(X_train_PCA1)\n",
        "y_pred_lr = logistic.predict(X_test_pca)\n",
        "logistic_train = metrics.accuracy_score(y_train,y_train_lr )\n",
        "logistic_accuracy = metrics.accuracy_score(y_val, y_pred_lr)\n",
        "\n",
        "print(\"Train Accuracy score: {}\".format(logistic_train))\n",
        "print(\"Test Accuracy score: {}\".format(logistic_accuracy))\n",
        "print(metrics.classification_report(y_val, y_pred_lr))"
      ],
      "metadata": {
        "id": "5rm2yX7cZFP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_matrix = pd.crosstab(pd.Series(y_val.values.flatten(), name='Actual' ),pd.Series(y_pred_lr, name='Predicted'))\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.title(\"Confusion Matrix on Logistic Regression\")\n",
        "sns.heatmap(con_matrix, cmap=\"Blues\", annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fG63-IChZl89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# svm\n",
        "y_train_svc = svc.predict(X_train_PCA1)\n",
        "y_pred_svc = svc.predict(X_test_pca)\n",
        "svc_train = metrics.accuracy_score(y_train,y_train_svc)\n",
        "svc_accuracy = metrics.accuracy_score(y_val, y_pred_svc)\n",
        "\n",
        "print(\"Train Accuracy score: {}\".format(svc_train))\n",
        "print(\"Test Accuracy score: {}\".format(svc_accuracy))\n",
        "print(metrics.classification_report(y_val, y_pred_svc))"
      ],
      "metadata": {
        "id": "r3SnYSWgZng8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_matrix = pd.crosstab(pd.Series(y_val.values.flatten(), name='Actual' ),pd.Series(y_pred_svc, name='Predicted'))\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.title(\"Confusion Matrix on SVC\")\n",
        "sns.heatmap(con_matrix, cmap=\"Blues\", annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L0l4f_ZYZr8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RF\n",
        "y_train_forest = random_forest.predict(X_train_PCA1)\n",
        "y_pred_forest = random_forest.predict(X_test_pca)\n",
        "random_forest_train = metrics.accuracy_score(y_train,y_train_forest)\n",
        "random_forest_accuracy = metrics.accuracy_score(y_val, y_pred_forest)\n",
        "\n",
        "print(\"Train Accuracy score: {}\".format(random_forest_train))\n",
        "print(\"Test Accuracy score: {}\".format(random_forest_accuracy))\n",
        "print(metrics.classification_report(y_val, y_pred_forest))"
      ],
      "metadata": {
        "id": "0pyiR-C1Zsld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_matrix = pd.crosstab(pd.Series(y_val.values.flatten(), name='Actual' ),pd.Series(y_pred_forest, name='Predicted'))\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.title(\"Confusion Matrix on Logistic Regression\")\n",
        "sns.heatmap(con_matrix, cmap=\"Blues\", annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R41U1ZE_ZtIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GBM\n",
        "y_train_gradient = Gradient.predict(X_train_PCA1)\n",
        "y_pred_gradient = Gradient.predict(X_test_pca)\n",
        "gradient_train = metrics.accuracy_score(y_train,y_train_gradient)\n",
        "gradient_accuracy = metrics.accuracy_score(y_val, y_pred_gradient)\n",
        "\n",
        "print(\"Train Accuracy score: {}\".format(gradient_train))\n",
        "print(\"Test Accuracy score: {}\".format(gradient_accuracy))\n",
        "print(metrics.classification_report(y_val, y_pred_gradient))"
      ],
      "metadata": {
        "id": "jhbjEOqVZtfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_matrix = pd.crosstab(pd.Series(y_val.values.flatten(), name='Actual' ),pd.Series(y_pred_gradient, name='Predicted'))\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.title(\"Confusion Matrix on Logistic Regression\")\n",
        "sns.heatmap(con_matrix, cmap=\"Blues\", annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SpAz9Or6ZtpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGB\n",
        "y_train_xgboost = xgb.predict(X_train_PCA1)\n",
        "y_pred_xgboost = xgb.predict(X_test_pca)\n",
        "xgb_train = metrics.accuracy_score(y_train,y_train_xgboost)\n",
        "xgb_accuracy = metrics.accuracy_score(y_val, y_pred_xgboost)\n",
        "\n",
        "print(\"Train Accuracy score: {}\".format(xgb_train))\n",
        "print(\"Test Accuracy score: {}\".format(xgb_accuracy))\n",
        "print(metrics.classification_report(y_val, y_pred_xgboost))"
      ],
      "metadata": {
        "id": "Ia8xoIRPZttc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "con_matrix = pd.crosstab(pd.Series(y_val.values.flatten(), name='Actual' ),pd.Series(y_pred_xgboost, name='Predicted'))\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.title(\"Confusion Matrix on Logistic Regression\")\n",
        "sns.heatmap(con_matrix, cmap=\"Blues\", annot=True, fmt='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sP_me7i0Ztwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Accuracy = [logistic_train,svc_train,random_forest_train,gradient_train,xgb_train]\n",
        "Test_Accuracy = [logistic_accuracy,svc_accuracy,random_forest_accuracy,gradient_accuracy,xgb_accuracy]\n",
        "data1 = {\n",
        "    'Algorithm': ['Logistic Regression','SVC','Random Forest Classifier','Gradient Boosting','XGBoost'],\n",
        "    'Train Accuracy':Train_Accuracy,\n",
        "    'Test Accuracy':Test_Accuracy\n",
        "}\n",
        "\n",
        "df1 = pd.DataFrame(data1)"
      ],
      "metadata": {
        "id": "6V7u16SdZzRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[\n",
        "    go.Bar(name='train set', x=data1['Algorithm'], y=data1['Train Accuracy'],text=np.round(data1['Train Accuracy'],2),textposition='outside'),\n",
        "    go.Bar(name='test set', x=data1['Algorithm'], y=data1['Test Accuracy'],text=np.round(data1['Test Accuracy'],2),textposition='outside')\n",
        "])\n",
        "\n",
        "fig.update_layout(barmode='group',title_text='Accuracy Comparison On Different Models',yaxis=dict(\n",
        "        title='Accuracy'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "O9m4ocwuZ-SL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}